{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timescale Vector (Postgres)\n",
    "\n",
    "This notebook shows how to use the Postgres vector database (`TimescaleVector`). You'll learn how to use TimescaleVector for semantic search, time-based vector search and how to create indexes to speed up queries.\n",
    "\n",
    "## What is Timescale Vector?\n",
    "**[Timescale Vector](https://www.timescale.com/ai) is PostgreSQL++ for AI applications.**\n",
    "\n",
    "Timescale Vector enables you to efficiently store and query billions of vector embeddings in `PostgreSQL`.\n",
    "- Enhances `pgvector` with faster and more accurate similarity search on 1B+ vectors via DiskANN inspired indexing algorithm.\n",
    "- Enables fast time-based vector search via automatic time-based partitioning and indexing.\n",
    "- Provides a familiar SQL interface for querying vector embeddings and relational data.\n",
    "\n",
    "Timescale Vector scales with you from POC to production:\n",
    "- Simplifies operations by enabling you to store relational metadata, vector embeddings, and time-series data in a single database.\n",
    "- Benefits from rock-solid PostgreSQL foundation with enterprise-grade feature liked streaming backups and replication, high-availability and row-level security.\n",
    "- Enables a worry-free experience with enterprise-grade security and compliance.\n",
    "\n",
    "## How to access Timescale Vector\n",
    "Timescale Vector is available on [Timescale](https://www.timescale.com/products), the cloud PostgreSQL platform. (There is no self-hosted version at this time.)\n",
    "\n",
    "- LangChain users get a 90-day free trial for Timescale Vector.\n",
    "- To get started, [signup](https://console.cloud.timescale.com/signup) to Timescale, create a new database and follow this notebook!\n",
    "- See the [installation instructions](https://github.com/timescale/python-vector) for more details on using Timescale Vector in python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pip install necessary packages\n",
    "!pip install timescale-vector\n",
    "!pip install openai\n",
    "!pip install tiktoken"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll use `OpenAIEmbeddings`, so let's load your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Run export OPENAI_API_KEY=sk-YOUR_OPENAI_API_KEY...\n",
    "# Get openAI api key by reading local .env file\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Get the API key and save it as an environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Loading Environment Variables\n",
    "from typing import List, Tuple\n",
    "#from dotenv import load_dotenv\n",
    "#load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll import the needed Python libraries and libraries from LangChain. Note that we import the `timescale-vector` library as well as the TimescaleVector vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timescale_vector\n",
    "from datetime import datetime, timedelta\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders.json_loader import JSONLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores.timescalevector import TimescaleVector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Similarity Search with Euclidean Distance (Default)\n",
    "\n",
    "We'll look at an example of doing a similarity search query on the State of the Union speech to find the most similar sentences to a given query sentence. We'll use the [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance) as our similarity metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text and split it into chunks\n",
    "loader = TextLoader(\"../../../extras/modules/state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to your PostgreSQL database, you'll need your service URI, which can be found in the cheatsheet file you downloaded after creating a new database. The URI will look something like this: `postgres://tsdbadmin:<password>@<id>.tsdb.cloud.timescale.com:<port>/tsdb?sslmode=require`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timescale Vector needs the service url to your cloud database. You can see this as soon as you create the \n",
    "# service in the cloud UI or in your credentials.sql file\n",
    "SERVICE_URL = os.environ['TIMESCALE_SERVICE_URL']\n",
    "\n",
    "# Specify directly if testing\n",
    "#SERVICE_URL = \"postgres://tsdbadmin:<password>@<id>.tsdb.cloud.timescale.com:<port>/tsdb?sslmode=require\"\n",
    "#SERVICE_URL = \"postgres://cevian@localhost:28815/timescaledb_vector\"\n",
    "\n",
    "# # You can get it from an enviornment variables. We suggest using a .env file.\n",
    "# import os\n",
    "\n",
    "# SERVICE_URL = os.environ.get(\"TIMESCALE_SERVICE_URL\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The TimescaleVector Module will try to create a table with the name of the collection.\n",
    "# So, make sure that the collection name is unique and the user has the permission to create a table.\n",
    "COLLECTION_NAME = \"state_of_the_union_test\"\n",
    "\n",
    "# Create a Timescale Vector instance from the collection of documents\n",
    "db = TimescaleVector.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=docs,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    service_url=SERVICE_URL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs_with_score = db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Score:  0.1845601444077416\n",
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.18456880908329532\n",
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.21735099605771857\n",
      "A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n",
      "\n",
      "And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n",
      "\n",
      "We can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n",
      "\n",
      "We’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n",
      "\n",
      "We’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n",
      "\n",
      "We’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.21742663435419274\n",
      "A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n",
      "\n",
      "And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n",
      "\n",
      "We can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n",
      "\n",
      "We’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n",
      "\n",
      "We’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n",
      "\n",
      "We’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Timescale Vector as a Retriever\n",
    "After initializing a TimescaleVector store, you can use it as a [retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TimescaleVector as a retriever\n",
    "retriever = store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['TimescaleVector', 'OpenAIEmbeddings'] metadata=None vectorstore=<langchain.vectorstores.timescalevector.TimescaleVector object at 0x133010310> search_type='similarity' search_kwargs={}\n"
     ]
    }
   ],
   "source": [
    "print(retriever)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example of using Timescale Vector as a retriever with the [RetrievalQA chain](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa) and the [stuff chain](https://python.langchain.com/docs/modules/chains/document/stuff).\n",
    "\n",
    "In this example, we'll ask the same query as above, but this time we'll pass the relevant documents returned from Timescale Vector to an LLM to use as context to answer our question.\n",
    "\n",
    "First we'll create our stuff chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GPT3.5 model\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature = 0.1, model = 'gpt-3.5-turbo-16k')\n",
    "\n",
    "# Initialize a RetrievalQA class from a stuff chain\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson?\"\n",
    "response = qa_stuff.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The President said that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson, who is one of our nation's top legal minds and will continue Justice Breyer's legacy of excellence.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Similarity Search with time-based filtering\n",
    "\n",
    "A key use case for Timescale Vector is efficient time-based vector search. Timescale Vector enables this by automatically partitioning vectors and associated metadata by time. This allows you to efficiently query vectors by both similarity to a query vector and time.\n",
    "\n",
    "Time-based vector search functionality is helpful for applications like:\n",
    "- Storing and retrieving LLM response history (e.g. chatbots)\n",
    "- Finding the most recent embeddings that are similar to a query vector (e.g recent news).\n",
    "- Constraining similarity search to a relevant time range (e.g asking time-based questions about a knowledge base)\n",
    "- Anomaly detection, where you want to find anomalous vectors within a specified time range.\n",
    "\n",
    "To illustrate how to use TimescaleVector's time-based vector search functionality, we'll ask questions about the git log history for TimescaleDB . We'll illustrate how to add documents with a time-based uuid and how run similarity searches with time range filters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract content and metadata from git log JSON\n",
    "First lets load in the git log data into a new collection in our PostgreSQL database named `timescale_commits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a helper funciton to create a uuid for a document and associated vector embedding based on its timestamp. We'll use this function to create a uuid for each git log entry.\n",
    "\n",
    "Important note: If you are working with documents and want the current date and time associated with vector for time-based search, you can skip this step. A uuid will be automatically generated when the documents are ingested by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timescale_vector import client\n",
    "# Function to take in a date string in the past and return a uuid v1\n",
    "def create_uuid(date_string: str):\n",
    "    if date_string is None:\n",
    "        return None\n",
    "    time_format = '%a %b %d %H:%M:%S %Y %z'\n",
    "    datetime_obj = datetime.strptime(date_string, time_format)\n",
    "    uuid = client.uuid_from_time(datetime_obj)\n",
    "    return str(uuid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define a metadata function to extract the relevant metadata from the JSON record. We'll pass this function to the JSONLoader. See the [JSON document loader docs](https://python.langchain.com/docs/modules/data_connection/document_loaders/json) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata extraction function to extract metadata from a JSON record\n",
    "def extract_metadata(record: dict, metadata: dict) -> dict:\n",
    "    metadata[\"id\"] = create_uuid(record[\"date\"])\n",
    "    metadata[\"date\"] = record[\"date\"]\n",
    "    metadata[\"author\"] = record[\"author\"]\n",
    "    metadata[\"commit_hash\"] = record[\"commit\"]\n",
    "    return metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can initialize the JSON loader to parse the JSON records. We also remove empty records for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from JSON file and extract metadata\n",
    "loader = JSONLoader(\n",
    "    file_path='../../../extras/modules/ts_git_log.json',\n",
    "    jq_schema='.commit_history[]',\n",
    "    text_content=False,\n",
    "    metadata_func=extract_metadata\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "# Remove documents with None date\n",
    "# This is required because we are using date as the primary key to partition the data by time\n",
    "documents = [doc for doc in documents if doc.metadata[\"date\"] is not None]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load documents and metadata into TimescaleVector vectorstore\n",
    "Now that we have prepared our documents, let's process them and load them, along with their vector embedding representations into our TimescaleVector vectorstore.\n",
    "\n",
    "Since this is a demo, we will only load the first 1000 records. In practice, you can load as many records as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first 100 elements from docs\n",
    "documents = documents[:1000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the CharacterTextSplitter to split the documents into smaller chunks if needed for easier embedding. Note that this splitting process retains the metadata for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into chunks for embedding\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll create a Timescale Vector instance from the collection of documents that we finished pre-processsing.\n",
    "\n",
    "First, we'll define a collection name, which will be the name of our table in the PostgreSQL database. \n",
    "\n",
    "We'll also define a time delta, which will be used to as the interval for partitioning the data by time. Each partition will consist of data for the specified length of time. We'll use 7 days for simplicity, but you can pick whatever value make sense for your use case -- for example if you query recent vectors frequently you might want to use a smaller time delta like 1 day, or if you query vectors over a decade long time period then you might want to use a larger time delta like 6 months or 1 year.\n",
    "\n",
    "Finally, we'll create the TimescaleVector instance. We specify the `ids` argument to be the `uuid` field in our metadata that we created in the pre-processing step above. We do this because we want the time part of our uuids to reflect past dates. If we wanted the current date and time to be associated with our document, we can remove the id argument and uuid's will be automatically created with the current date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure the time delta for the partitioning the table\n",
    "timeDeltaArgDays = \"days\"\n",
    "timeDeltaArgDaysValue = 7\n",
    "kwargs = {timeDeltaArgDays: timeDeltaArgDaysValue}\n",
    "\n",
    "# Define collection name\n",
    "COLLECTION_NAME = \"timescale_commits\"\n",
    "\n",
    "# Create a Timescale Vector instance from the collection of documents\n",
    "db = TimescaleVector.from_documents(\n",
    "      embedding=embeddings,\n",
    "      ids = [doc.metadata[\"id\"] for doc in docs],\n",
    "      documents=docs,\n",
    "      collection_name=COLLECTION_NAME,\n",
    "      service_url=SERVICE_URL,\n",
    "      time_partition_interval=timedelta(**kwargs),)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying vectors by time and similarity\n",
    "\n",
    "Now that we have loaded our documents into TimescaleVector, we can query them by time and similarity.\n",
    "\n",
    "TimescaleVector provides 3 methods for querying vectors doing similarity search with time-based filtering.\n",
    "\n",
    "- Method 1: Filter within a provided start date and end date.\n",
    "- Method 2: Filter within a provided start date and time delta later.\n",
    "- Method 3: Filter within a provided end_date and time delta earlier.\n",
    "\n",
    "Let's take a look at each method below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time filter variables\n",
    "# Start date = 1 Auguest 2023, 22:10:35\n",
    "start_dt = datetime(2023, 8, 1, 22, 10, 35)\n",
    "# End date = 30 Auguest 2023, 22:10:35\n",
    "end_dt = datetime(2023, 8, 30, 22, 10, 35)\n",
    "# Time delta = 7 days\n",
    "td = timedelta(days=7)\n",
    "\n",
    "query = \"What's new with TimescaleDB functions?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Score:  0.17487859725952148\n",
      "Date:  Tue Aug 29 18:13:24 2023 +0200\n",
      "{\"commit\": \" e4facda540286b0affba47ccc63959fefe2a7b26\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Aug 29 18:13:24 2023 +0200\", \"change summary\": \"Add compatibility layer for _timescaledb_internal functions\", \"change details\": \"With timescaledb 2.12 all the functions present in _timescaledb_internal were moved into the _timescaledb_functions schema to improve schema security. This patch adds a compatibility layer so external callers of these internal functions will not break and allow for more flexibility when migrating. \"}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.1750067576770027\n",
      "Date:  Tue Aug 29 18:13:24 2023 +0200\n",
      "{\"commit\": \" e4facda540286b0affba47ccc63959fefe2a7b26\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Aug 29 18:13:24 2023 +0200\", \"change summary\": \"Add compatibility layer for _timescaledb_internal functions\", \"change details\": \"With timescaledb 2.12 all the functions present in _timescaledb_internal were moved into the _timescaledb_functions schema to improve schema security. This patch adds a compatibility layer so external callers of these internal functions will not break and allow for more flexibility when migrating. \"}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.18100780248641968\n",
      "Date:  Sun Aug 20 22:47:10 2023 +0200\n",
      "{\"commit\": \" 0a66bdb8d36a1879246bd652e4c28500c4b951ab\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Sun Aug 20 22:47:10 2023 +0200\", \"change summary\": \"Move functions to _timescaledb_functions schema\", \"change details\": \"To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - to_unix_microseconds(timestamptz) - to_timestamp(bigint) - to_timestamp_without_timezone(bigint) - to_date(bigint) - to_interval(bigint) - interval_to_usec(interval) - time_to_internal(anyelement) - subtract_integer_from_now(regclass, bigint) \"}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.18102192878723145\n",
      "Date:  Sun Aug 20 22:47:10 2023 +0200\n",
      "{\"commit\": \" 0a66bdb8d36a1879246bd652e4c28500c4b951ab\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Sun Aug 20 22:47:10 2023 +0200\", \"change summary\": \"Move functions to _timescaledb_functions schema\", \"change details\": \"To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - to_unix_microseconds(timestamptz) - to_timestamp(bigint) - to_timestamp_without_timezone(bigint) - to_date(bigint) - to_interval(bigint) - interval_to_usec(interval) - time_to_internal(anyelement) - subtract_integer_from_now(regclass, bigint) \"}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Query for vectors between start_date and end_date\n",
    "docs_with_score = db.similarity_search_with_score(query, start_date=start_dt, end_date=end_dt)\n",
    "\n",
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(\"Date: \", doc.metadata[\"date\"])\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Score:  0.1844592470575277\n",
      "Date:  Thu Aug 3 14:30:23 2023 +0300\n",
      "{\"commit\": \" 7aeed663b9c0f337b530fd6cad47704a51a9b2ec\", \"author\": \"Dmitry Simonenko<dmitry@timescale.com>\", \"date\": \"Thu Aug 3 14:30:23 2023 +0300\", \"change summary\": \"Feature flags for TimescaleDB features\", \"change details\": \"This PR adds several GUCs which allow to enable/disable major timescaledb features:  - enable_hypertable_create - enable_hypertable_compression - enable_cagg_create - enable_policy_create \"}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.18464880081124158\n",
      "Date:  Thu Aug 3 14:30:23 2023 +0300\n",
      "{\"commit\": \" 7aeed663b9c0f337b530fd6cad47704a51a9b2ec\", \"author\": \"Dmitry Simonenko<dmitry@timescale.com>\", \"date\": \"Thu Aug 3 14:30:23 2023 +0300\", \"change summary\": \"Feature flags for TimescaleDB features\", \"change details\": \"This PR adds several GUCs which allow to enable/disable major timescaledb features:  - enable_hypertable_create - enable_hypertable_compression - enable_cagg_create - enable_policy_create \"}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.2050052163001752\n",
      "Date:  Mon Aug 7 18:31:40 2023 +0200\n",
      "{\"commit\": \" 07762ea4cedefc88497f0d1f8712d1515cdc5b6e\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Mon Aug 7 18:31:40 2023 +0200\", \"change summary\": \"Test timescaledb debian 12 packages in CI\", \"change details\": \"\"}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.20508549152785638\n",
      "Date:  Mon Aug 7 18:31:40 2023 +0200\n",
      "{\"commit\": \" 07762ea4cedefc88497f0d1f8712d1515cdc5b6e\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Mon Aug 7 18:31:40 2023 +0200\", \"change summary\": \"Test timescaledb debian 12 packages in CI\", \"change details\": \"\"}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Query for vectors between start_dt and a time delta td later\n",
    "# Most relevant vectors between 1 August and 7 days later\n",
    "docs_with_score = db.similarity_search_with_score(query, start_date=start_dt, time_delta=td)\n",
    "\n",
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(\"Date: \", doc.metadata[\"date\"])\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Score:  0.17496256977542668\n",
      "Date:  Tue Aug 29 18:13:24 2023 +0200\n",
      "{\"commit\": \" e4facda540286b0affba47ccc63959fefe2a7b26\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Aug 29 18:13:24 2023 +0200\", \"change summary\": \"Add compatibility layer for _timescaledb_internal functions\", \"change details\": \"With timescaledb 2.12 all the functions present in _timescaledb_internal were moved into the _timescaledb_functions schema to improve schema security. This patch adds a compatibility layer so external callers of these internal functions will not break and allow for more flexibility when migrating. \"}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.17509043216704734\n",
      "Date:  Tue Aug 29 18:13:24 2023 +0200\n",
      "{\"commit\": \" e4facda540286b0affba47ccc63959fefe2a7b26\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Aug 29 18:13:24 2023 +0200\", \"change summary\": \"Add compatibility layer for _timescaledb_internal functions\", \"change details\": \"With timescaledb 2.12 all the functions present in _timescaledb_internal were moved into the _timescaledb_functions schema to improve schema security. This patch adds a compatibility layer so external callers of these internal functions will not break and allow for more flexibility when migrating. \"}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.18503056853827282\n",
      "Date:  Tue Aug 29 10:49:47 2023 +0200\n",
      "{\"commit\": \" a9751ccd5eb030026d7b975d22753f5964972389\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Aug 29 10:49:47 2023 +0200\", \"change summary\": \"Move partitioning functions to _timescaledb_functions schema\", \"change details\": \"To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - get_partition_for_key(val anyelement) - get_partition_hash(val anyelement) \"}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.1851393470085042\n",
      "Date:  Tue Aug 29 10:49:47 2023 +0200\n",
      "{\"commit\": \" a9751ccd5eb030026d7b975d22753f5964972389\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Aug 29 10:49:47 2023 +0200\", \"change summary\": \"Move partitioning functions to _timescaledb_functions schema\", \"change details\": \"To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - get_partition_for_key(val anyelement) - get_partition_hash(val anyelement) \"}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Query for vectors between end_dt and a time delta td earlier\n",
    "# Most relevant vectors between 30 August and 7 days earlier\n",
    "docs_with_score = db.similarity_search_with_score(query, end_date=end_dt, time_delta=td)\n",
    "\n",
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(\"Date: \", doc.metadata[\"date\"])\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each result above, only vectors within the specified time range are returned. These queries are very efficient as they only need to search the relevant partitions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use this functionality for question answering, where we want to find the most relevant vectors within a specified time range to use as context for answering a question. Let's take a look at an example below, using Timescale Vector as a retriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The timescaledb functions have undergone some changes. In one patch, the support functions for histogram, first, and last have been moved into the _timescaledb_functions schema. This change should be transparent for users who have objects using those aggregates. \n",
      "\n",
      "In another patch, the type support functions have also been moved into the _timescaledb_functions schema. \n",
      "\n",
      "Additionally, a compatibility layer has been added for the _timescaledb_internal functions. These functions were moved into the _timescaledb_functions schema in order to improve schema security. The compatibility layer ensures that external callers of these internal functions will not break and allows for more flexibility when migrating.\n"
     ]
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature = 0.1, model = 'gpt-3.5-turbo-16k')\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "query = \"What's new with the timescaledb functions?\"\n",
    "response = qa_stuff.run(query)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using ANN Search Indexes to Speed Up Queries\n",
    "\n",
    "You can speed up similarity queries by creating an index on the embedding column. You should only do this once you have ingested a large part of your data.\n",
    "\n",
    "Timescale Vector supports the following indexes:\n",
    "- timescale_vector_index: a disk-ann inspired graph index for fast similarity search (default).\n",
    "- pgvector's HNSW index: a hierarchical navigable small world graph index for fast similarity search.\n",
    "- pgvector's IVFFLAT index: an inverted file index for fast similarity search. This index is not recommended for high-dimensional embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an existing TimescaleVector store\n",
    "COLLECTION_NAME = \"timescale_commits\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = TimescaleVector(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    service_url=SERVICE_URL,\n",
    "    embedding_function=embeddings,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `create_index()` function without additional arguments will create a timescale_vector_index by default, using the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index\n",
    "# by default this will create a Timescale Vector (DiskANN) index\n",
    "db.create_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify the parameters for the index. See the Timescale Vector documentation for a full discussion of the different parameters and their effects on performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index, fails if the index exists\n",
    "db.create_index(index_type=TimescaleVector.IndexType.TIMESCALE_VECTOR,\n",
    "                 index_name = \"tsv_index_2\", \n",
    "                     **{TimescaleVector.IndexOptions.TSV_MAX_ALPHA.value:1.0, \n",
    "                     TimescaleVector.IndexOptions.TSV_NUM_NEIGHBORS.value:50})   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can also specify the index type by passing the `index_type` argument to the `create_index()` function. Here we'll also use the `index_name` argument to provide a name for the index so that we can create multiple indexes on the same table and compare the performance if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an HNSW index  \n",
    "db.create_index(index_type=TimescaleVector.IndexType.PGVECTOR_HNSW,\n",
    "                index_name=\"pgvector_hnsw_index\",\n",
    "                **{TimescaleVector.IndexOptions.PGV_HNSW_M.value: 16, \n",
    "                   TimescaleVector.IndexOptions.PGV_HNSW_EF.value: 64}\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an IVFFLAT index\n",
    "db.create_index(index_type=TimescaleVector.IndexType.PGVECTOR_IVFFLAT,\n",
    "                    index_name=\"ivfflat_index\",\n",
    "                    **{TimescaleVector.IndexOptions.PGV_IVFLAT_NUM_LISTS.value:20},\n",
    "                    **{TimescaleVector.IndexOptions.PGV_IVFLAT_NUM_RECORDS.value:1000})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Working with an existing TimescaleVector vectorstore\n",
    "\n",
    "In the examples above, we created a vectorstore from a collection of documents. However, often we want to work insert data into and query data from an existing vectorstore. Let's see how to initialize, add documents to, and query an existing collection of documents in a TimescaleVector vector store.\n",
    "\n",
    "To work with an existing Timescale Vector store, we need to know the name of the table we want to query (`COLLECTION_NAME`) and the URL of the cloud PostgreSQL database (`SERVICE_URL`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an existing TimescaleVector store\n",
    "COLLECTION_NAME = \"state_of_the_union_test\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "store = TimescaleVector(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    service_url=SERVICE_URL,\n",
    "    embedding_function=embeddings,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load new data into the table, we use the `add_document()` function. This function takes a list of documents and a list of metadata. The metadata must contain a unique id for each document. \n",
    "\n",
    "If you want your documents to be associated with the current date and time, you do not need to create a list of ids. A uuid will be automatically generated for each document.\n",
    "\n",
    "If you want your documents to be associated with a past date and time, you can create a list of ids using the `uuid_from_time` function in the `timecale-vector` python library, as shown in Section 2 above. This function takes a datetime object and returns a uuid with the date and time encoded in the uuid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ae0cc1de-4dee-11ee-8c82-de1e4b2a0118']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add documents to a collection in TimescaleVector\n",
    "ids = store.add_documents([Document(page_content=\"foo\")])\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the vectorstore for similar documents\n",
    "docs_with_score = store.similarity_search_with_score(\"foo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Document(page_content='foo', metadata={}), 5.006789860928507e-06)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_with_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Document(page_content='foo', metadata={}), 5.006789860928507e-06)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_with_score[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Data \n",
    "\n",
    "You can delete data by uuid or by a filter on the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = store.add_documents([Document(page_content=\"Bar\")])\n",
    "\n",
    "store.delete(ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting using metadata is especially useful if you want to periodically update information scraped from a particular source, or particular date or some other metadata attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['64b491fa-4def-11ee-8c82-de1e4b2a0118']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.add_documents([Document(page_content=\"Hello World\", metadata={\"source\": \"www.example.com/hello\"})])\n",
    "store.add_documents([Document(page_content=\"Adios\", metadata={\"source\": \"www.example.com/adios\"})])\n",
    "\n",
    "store.delete_by_metadata({\"source\": \"www.example.com/adios\"})\n",
    "\n",
    "store.add_documents([Document(page_content=\"Adios, but newer!\", metadata={\"source\": \"www.example.com/adios\"})])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overriding a vectorstore\n",
    "\n",
    "If you have an existing collection, you override it by doing `from_documents` and setting `pre_delete_collection` = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = TimescaleVector.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    service_url=SERVICE_URL,\n",
    "    pre_delete_collection=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_with_score = db.similarity_search_with_score(\"foo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Document(page_content='A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \\n\\nWe can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \\n\\nWe’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \\n\\nWe’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \\n\\nWe’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.', metadata={'source': '../../../extras/modules/state_of_the_union.txt'}),\n",
       " 0.2404394973658165)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_with_score[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
